\section{Peržiūros roboto architektūros}

Šiame skyriuje analizuojamos mokslinėje literatūroje aprašytos saityno peržiūros robotų realizacijos -- pagrindiniai komponentai, jų funkcinės atsakomybės, charakteristikos, atliekama palyginamoji analizė tarp skirtingų aprašytų sistemų.

\subsection{Peržiūros roboto komponentai}

M.Najorc ir C. Olston mokslinė saityno peržiūros sistemų robotų (\cite{StanfWebCrawl}) formalizuoja anksčiau literatūroje aprašytas tokių sistemų dizaino specifikas. Joje nusakoma išskirstyto peržiūros roboto architektūra -- skirtingose mašinose egzistuojantys žvalgymo procesai, kiekvienas jų turintis keletą lygiagrečiai veikiančių agentų gijų, kurios atlieka kartotinius žvalgymo ciklo žingsius, kuriuose dalyvauja išskiriami pagrindiniai 8 struktūriniai sistemos komponentai.

\subsubsection{„Pasienis“}

„Pasienio“ duomenų struktūra (angl. -- \textit{URL Frontier}) saugo URL\footnote{URL - Uniform Resource Locator} adresų sąrašą, kurie bus aplankyti, iš šio sąrašo paduodamas adresas žvalgymo agento gijai pagal atitinkamas žvalgymo mandagumo (angl. -- \textit{Politeness}) ir prioritizavimo (angl. -- \textit{Priority}) politikas (\cite{StanfWebCrawl}. Tai viena iš pagrindinių žvalgymo roboto būsenos duomenų struktūrų. Jai keliami šie pagrindiniai funkcionalumo reikalavimai:
\begin{itemize}
    \item Pridėti URL adresą į sąrašą
    \item Nuskaityti URL adresą iš sąrašo
\end{itemize}

\subsubsection{HTTP parsiuntimo modulis}

Žvalgymo agentui gavus URL adresą iškviečiamas HTTP modulis, kuris pirmiausia kreipiasi į \textit{DNS adreso išaiškinimo} komponentą tam, jog būtų nustatytas URL resurso serverio vardo IP protokolo adresas \cite{StanfWebCrawl}. Šis veiksmas reikalingas tam, kad būtų minimizuotas HTTP užklausos atsakymo laikas (išvengiama DNS išaiškinimo užklausų į išorinius serverius).

\subsubsection{Saityno nuorodų ištraukiklis}

Šis komponentas (angl. -- \textit{Link Extractor}) nuskaito parsiųsto HTML dokumento turinį ir išgauna visas HTML nuorodas tiek į išorinius (angl. -- \textit{Offsite Links}), tiek į vidinius (\textit{In-site Links}) žiniatinklio serverio puslapius \cite{StanfWebCrawl}.

\subsubsection{Adresų skirstiklis}

Šis modulis (angl. -- \textit{URL Distributor}) atsakingas už išgautų nuorodų priskyrimą atitinkamiems žvalgymo procesams \cite{StanfWebCrawl}.

\subsubsection{Adresų filtras}

Komponentas, kuris filtruoja priskirtus URL adresus ir gali išmesti taisyklių neatitinkančias nuorodas (pvz.: puslapiai, įtraukti į juodąjį sąrašą) \cite{StanfWebCrawl}. Taisyklės gali būti specializuotos kiekvienam žvalgymui atskirai.

\subsubsection{Dublikatų šalintojas}

Roboto dalis, kuri atlieką testą, ar URL nuoroda dar nebuvo aplankyta peržiūros metu, pagrindiniai keliami funkcionamulo reikalavimai \cite{StanfWebCrawl}:
\begin{itemize}
    \item Pridėti URL adreso aplankymo indikatorių į sąrašą
    \item Atlikti URL priklausymo sąrašui testą
\end{itemize}

\subsubsection{Adresų prioritizuotojas}

Komponentas (angl. -- \textit{URL Prioritizer}), kuris kiekvienam URL adresui priskiria tam tikrą prioritetą pagal specializuotus saityno peržiūros roboto sistemos pasirinkimo politikos faktorius, tokius kaip nustatomas puslapio svarbos laipsnis ar puslapio keitimosi greičio faktorius \cite{StanfWebCrawl}.


\subsection{Peržiūros vykdymo ciklas}

Atsivelgus į 3.1 poskyrio struktūrinius komponentus pagal \cite{StanfWebCrawl} pasiūlytą schematinį dizainą, galima sudaryti veiklos diagramą, parodančią sistemos ciklinį funkcionavimą.

\input{chapters/figures/web_crawler_activity_diagram}

\subsection{Literatūroje aprašytų robotų palyginamoji analizė}

Šiame skyriuje pristatomi esminiai inžineriniai peržiūros robotų architektūrų iššūkiai ir apžvelgiama keletas žinomiausių akademiniuose šaltiniuose aprašytų saityno peržiūros robotų architektūrų siekiant palyginti, kaip kiekvienas jų sprendžia minėtasias problemas.

\subsubsection{Peržiūros robotų archiktektūros iššūkiai}

Nors koncepcinis peržiūros sistemų algoritmas, aprašytas 1 skyriuje, yra labai paprastas, tokių sistemų problemos kyla sprendžiant išplėtimo iššūkius -- siekiant peržiūrėti milijardus svetainių per pagrįstai trumpą laiką ir išlaikyti peržiūrėtų svetainių naujausią galimą kopiją \cite{WCArchitectureMicrosoft}. Pagal \cite{WCArchitectureMicrosoft} apžvalgą, galima būtų iškelti šiuos pagrindinius peržiūros robotų architektūrų iššūkius:

\begin{itemize}
  \item Sugebėti vykdyti peržiūros procesą išskirstytai ir lygiagrečiai, tačiau vykdyti tai etiškai neapkraunant žiniatinklio serverio (etiško žvalgymo politika)
  \item Priklausymo sąrašui testas -- svarbu sugebėti efektyviai patikrinti (duomenų struktūros), ar URL adresas jau buvo peržiūrėtas
  \item Puslapio turinio dublikatų testas
  \item „Pasienio“ duomenų struktūra turi gebėti saugoti milijardus URL adresų
\end{itemize}

\input{chapters/architectures/polybot}
\input{chapters/architectures/mercator}

\subsubsection{„BUbiNG“ didelio masto žvalgymo sistemos architektūra}